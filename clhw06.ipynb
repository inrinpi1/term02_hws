{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f099ce50-a1aa-4502-b981-c0d1c85f77c7",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "Попробуйте поработать с датасетом юридических текстов. В датасете всего две важных колонки признаков: заголовок дела и его текст, а целевая переменная - case_outcome (мультиклассовая классификация). \n",
    "\n",
    "В базовом варианте можно оставить только текст дела, если хотите поинтереснее - можно попробовать распарсить case_title, добыв оттуда дополнительные признаки. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df3683-30fb-46f4-8c4f-5beee132a036",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/amohankumar/legal-text-classification-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b2daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7767d7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kiril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kiril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61907767-c695-4581-9793-044286450797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_outcome</th>\n",
       "      <th>case_title</th>\n",
       "      <th>case_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Case1</td>\n",
       "      <td>cited</td>\n",
       "      <td>Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case2</td>\n",
       "      <td>cited</td>\n",
       "      <td>Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Case3</td>\n",
       "      <td>cited</td>\n",
       "      <td>Colgate Palmolive Co v Cussons Pty Ltd (1993) ...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Case4</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dais Studio Pty Ltd v Bullett Creative Pty Ltd...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Case5</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dr Martens Australia Pty Ltd v Figgins Holding...</td>\n",
       "      <td>The preceding general principles inform the ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_id case_outcome                                         case_title  \\\n",
       "0   Case1        cited  Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...   \n",
       "1   Case2        cited  Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...   \n",
       "2   Case3        cited  Colgate Palmolive Co v Cussons Pty Ltd (1993) ...   \n",
       "3   Case4        cited  Dais Studio Pty Ltd v Bullett Creative Pty Ltd...   \n",
       "4   Case5        cited  Dr Martens Australia Pty Ltd v Figgins Holding...   \n",
       "\n",
       "                                           case_text  \n",
       "0  Ordinarily that discretion will be exercised s...  \n",
       "1  The general principles governing the exercise ...  \n",
       "2  Ordinarily that discretion will be exercised s...  \n",
       "3  The general principles governing the exercise ...  \n",
       "4  The preceding general principles inform the ex...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('legal_text_classification.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7b80472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24985 entries, 0 to 24984\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   case_id       24985 non-null  object\n",
      " 1   case_outcome  24985 non-null  object\n",
      " 2   case_title    24985 non-null  object\n",
      " 3   case_text     24809 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 780.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "934e2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86585ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cited', 'applied', 'followed', 'referred to', 'related',\n",
       "       'considered', 'discussed', 'distinguished', 'affirmed', 'approved'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.case_outcome.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab230246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_outcome\n",
       "cited            12110\n",
       "referred to       4363\n",
       "applied           2438\n",
       "followed          2252\n",
       "considered        1699\n",
       "discussed         1018\n",
       "distinguished      603\n",
       "related            112\n",
       "approved           108\n",
       "affirmed           106\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.case_outcome.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406803f3",
   "metadata": {},
   "source": [
    "Выборка несбалансирована."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a9f560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\" \n",
    "    Предобработка текстовых данных.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text) # Удаление ссылок\n",
    "    text = text.lower() # Приведение к нижнему регистру\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Удаление пунктуации\n",
    "    tokens = nltk.word_tokenize(text) # Токенизация\n",
    "    tokens = [word for word in tokens if word not in stop_words] # Удаление стоп-слов\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens] # Лемматизация\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd0783a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(choice_transformer, choice_ngrams):\n",
    "    \"\"\" \n",
    "    Возвращает векторизатор текста с указанными параметрами. \n",
    "    Параметр max_features=5000 выбран для оптимизации скорости обработки данных и не должен существенно влиять на качество модели.\n",
    "    \"\"\"\n",
    "    if choice_transformer == 'tfidf':\n",
    "        text_transformer = TfidfVectorizer(ngram_range=choice_ngrams, max_features=5000)\n",
    "    else:\n",
    "        text_transformer = CountVectorizer(ngram_range=choice_ngrams, max_features=5000)\n",
    "\n",
    "    return text_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b15e6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(model):\n",
    "    \"\"\"\n",
    "    Обучает переданную модель и выводит оценки точности на тестовом и обучающем наборах данных.\n",
    "    \"\"\"\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    \n",
    "    ypredtest = model.predict(Xtest)\n",
    "    ypredtrain = model.predict(Xtrain)\n",
    "    \n",
    "    print(accuracy_score(ytest, ypredtest), accuracy_score(ytrain, ypredtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29cd0609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_outcome</th>\n",
       "      <th>case_title</th>\n",
       "      <th>case_text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Case1</td>\n",
       "      <td>cited</td>\n",
       "      <td>Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "      <td>ordinarily discretion exercised cost follow ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case2</td>\n",
       "      <td>cited</td>\n",
       "      <td>Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "      <td>general principle governing exercise discretio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Case3</td>\n",
       "      <td>cited</td>\n",
       "      <td>Colgate Palmolive Co v Cussons Pty Ltd (1993) ...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "      <td>ordinarily discretion exercised cost follow ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Case4</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dais Studio Pty Ltd v Bullett Creative Pty Ltd...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "      <td>general principle governing exercise discretio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Case5</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dr Martens Australia Pty Ltd v Figgins Holding...</td>\n",
       "      <td>The preceding general principles inform the ex...</td>\n",
       "      <td>preceding general principle inform exercise di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_id case_outcome                                         case_title  \\\n",
       "0   Case1        cited  Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...   \n",
       "1   Case2        cited  Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...   \n",
       "2   Case3        cited  Colgate Palmolive Co v Cussons Pty Ltd (1993) ...   \n",
       "3   Case4        cited  Dais Studio Pty Ltd v Bullett Creative Pty Ltd...   \n",
       "4   Case5        cited  Dr Martens Australia Pty Ltd v Figgins Holding...   \n",
       "\n",
       "                                           case_text  \\\n",
       "0  Ordinarily that discretion will be exercised s...   \n",
       "1  The general principles governing the exercise ...   \n",
       "2  Ordinarily that discretion will be exercised s...   \n",
       "3  The general principles governing the exercise ...   \n",
       "4  The preceding general principles inform the ex...   \n",
       "\n",
       "                                           processed  \n",
       "0  ordinarily discretion exercised cost follow ev...  \n",
       "1  general principle governing exercise discretio...  \n",
       "2  ordinarily discretion exercised cost follow ev...  \n",
       "3  general principle governing exercise discretio...  \n",
       "4  preceding general principle inform exercise di...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['processed'] = data['case_text'].apply(preprocess_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a08759fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['processed']  \n",
    "y = data['case_outcome']  \n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45da32",
   "metadata": {},
   "source": [
    "TF-IDF unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0a039acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = feature_engineering('tfidf', (1, 1))\n",
    "\n",
    "clfLR = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor), \n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "clfSVC = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor), \n",
    "    (\"classifier\", SVC(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "547f5997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5330511890366788 0.6169698191162393\n",
      "0.586658605401048 0.7908500025192724\n"
     ]
    }
   ],
   "source": [
    "modelfit(clfLR)\n",
    "modelfit(clfSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0445497",
   "metadata": {},
   "source": [
    "TF-IDF bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "18236c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = feature_engineering('tfidf', (2, 2))\n",
    "\n",
    "clfLR = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor), \n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "clfSVC = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor), \n",
    "    (\"classifier\", SVC(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "27805e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5322450624748085 0.6055323222653298\n",
      "0.5751713018943975 0.7681261651635007\n"
     ]
    }
   ],
   "source": [
    "modelfit(clfLR)\n",
    "modelfit(clfSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "10dce473",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = feature_engineering('tfidf', (1, 2))\n",
    "\n",
    "clfLR = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor), \n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "clfSVC = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor), \n",
    "    (\"classifier\", SVC(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "06e1d9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5388956066102378 0.6168690482188743\n",
      "0.5900846432889963 0.7898422935456241\n"
     ]
    }
   ],
   "source": [
    "modelfit(clfLR)\n",
    "modelfit(clfSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253fbdbb",
   "metadata": {},
   "source": [
    "BOW unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c9245c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = feature_engineering('bow', (1, 1))\n",
    "\n",
    "clfLR = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))]\n",
    ")\n",
    "\n",
    "clfSVC = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", SVC(random_state=42))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ec88bb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5342603788794841 0.8828034463646899\n",
      "0.5004030632809351 0.5465813473068978\n"
     ]
    }
   ],
   "source": [
    "modelfit(clfLR)\n",
    "modelfit(clfSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a1efa4",
   "metadata": {},
   "source": [
    "BOW bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f993f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = feature_engineering('bow', (2, 2))\n",
    "\n",
    "clfLR = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))]\n",
    ")\n",
    "\n",
    "clfSVC = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", SVC(random_state=42))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2b607447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5439338976219267 0.8285887035824054\n",
      "0.5110842402257154 0.5551972590315917\n"
     ]
    }
   ],
   "source": [
    "modelfit(clfLR)\n",
    "modelfit(clfSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d89afc",
   "metadata": {},
   "source": [
    "BOW Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cd912349",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = feature_engineering('bow', (1, 1))\n",
    "\n",
    "bagging = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", BaggingClassifier(random_state=42, n_jobs=-1))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3e936c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5705360741636437 0.9421575049125812\n"
     ]
    }
   ],
   "source": [
    "modelfit(bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1c21f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = feature_engineering('bow', (2, 2))\n",
    "\n",
    "bagging = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", BaggingClassifier(random_state=42, n_jobs=-1))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "dcfbfebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5634824667472793 0.9375220436337985\n"
     ]
    }
   ],
   "source": [
    "modelfit(bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f710b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = feature_engineering('bow', (1, 2))\n",
    "\n",
    "bagging = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", BaggingClassifier(random_state=42, n_jobs=-1))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e7b0e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5745667069729947 0.9431148284375472\n"
     ]
    }
   ],
   "source": [
    "modelfit(bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d7604",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70aff8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.592503022974607 0.9577266085554492\n"
     ]
    }
   ],
   "source": [
    "preprocessor = feature_engineering('bow', (1, 1))\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier(random_state=42, n_jobs=-1))]\n",
    ")\n",
    "\n",
    "modelfit(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8d5ba875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5923014913341395 0.9575250667607195\n"
     ]
    }
   ],
   "source": [
    "preprocessor = feature_engineering('bow', (2, 2))\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier(random_state=42, n_jobs=-1))]\n",
    ")\n",
    "\n",
    "modelfit(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1a6f4e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5929060862555421 0.9577266085554492\n"
     ]
    }
   ],
   "source": [
    "preprocessor = feature_engineering('bow', (1, 2))\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier(random_state=42, n_jobs=-1))]\n",
    ")\n",
    "\n",
    "modelfit(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e19340",
   "metadata": {},
   "source": [
    "1. Комбинация униграмм и биграмм ((1, 2)) обычно дает лучшие результаты.\n",
    "2. TF-IDF в целом показывает более высокие результаты, чем BOW.\n",
    "3. Среди использованных классификаторов (логистическая регрессия, SVC, бэггинг, случайный лес), случайный лес показывает одни из лучших результатов, хотя стоит также отметить высокий уровень переобучения (большая разница между точностью на тренировочной и тестовой выборках).  \n",
    "SVC с TF-IDF (униграммы и биграммы) оказался почти так же эффективен, как и Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872990c",
   "metadata": {},
   "source": [
    "Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a21df732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7f26565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_doc2vec(text):\n",
    "    \"\"\" \n",
    "    Предобработка текстовых данных.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Удаление ссылок\n",
    "    text = text.lower()  # Приведение к нижнему регистру\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Удаление пунктуации\n",
    "    tokens = nltk.word_tokenize(text)  # Токенизация\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Удаление стоп-слов\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Лемматизация\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4dd6e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_outcome</th>\n",
       "      <th>case_title</th>\n",
       "      <th>case_text</th>\n",
       "      <th>processed</th>\n",
       "      <th>processed_doc2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Case1</td>\n",
       "      <td>cited</td>\n",
       "      <td>Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "      <td>ordinarily discretion exercised cost follow ev...</td>\n",
       "      <td>[ordinarily, discretion, exercised, cost, foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case2</td>\n",
       "      <td>cited</td>\n",
       "      <td>Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "      <td>general principle governing exercise discretio...</td>\n",
       "      <td>[general, principle, governing, exercise, disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Case3</td>\n",
       "      <td>cited</td>\n",
       "      <td>Colgate Palmolive Co v Cussons Pty Ltd (1993) ...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "      <td>ordinarily discretion exercised cost follow ev...</td>\n",
       "      <td>[ordinarily, discretion, exercised, cost, foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Case4</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dais Studio Pty Ltd v Bullett Creative Pty Ltd...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "      <td>general principle governing exercise discretio...</td>\n",
       "      <td>[general, principle, governing, exercise, disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Case5</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dr Martens Australia Pty Ltd v Figgins Holding...</td>\n",
       "      <td>The preceding general principles inform the ex...</td>\n",
       "      <td>preceding general principle inform exercise di...</td>\n",
       "      <td>[preceding, general, principle, inform, exerci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_id case_outcome                                         case_title  \\\n",
       "0   Case1        cited  Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...   \n",
       "1   Case2        cited  Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...   \n",
       "2   Case3        cited  Colgate Palmolive Co v Cussons Pty Ltd (1993) ...   \n",
       "3   Case4        cited  Dais Studio Pty Ltd v Bullett Creative Pty Ltd...   \n",
       "4   Case5        cited  Dr Martens Australia Pty Ltd v Figgins Holding...   \n",
       "\n",
       "                                           case_text  \\\n",
       "0  Ordinarily that discretion will be exercised s...   \n",
       "1  The general principles governing the exercise ...   \n",
       "2  Ordinarily that discretion will be exercised s...   \n",
       "3  The general principles governing the exercise ...   \n",
       "4  The preceding general principles inform the ex...   \n",
       "\n",
       "                                           processed  \\\n",
       "0  ordinarily discretion exercised cost follow ev...   \n",
       "1  general principle governing exercise discretio...   \n",
       "2  ordinarily discretion exercised cost follow ev...   \n",
       "3  general principle governing exercise discretio...   \n",
       "4  preceding general principle inform exercise di...   \n",
       "\n",
       "                                   processed_doc2vec  \n",
       "0  [ordinarily, discretion, exercised, cost, foll...  \n",
       "1  [general, principle, governing, exercise, disc...  \n",
       "2  [ordinarily, discretion, exercised, cost, foll...  \n",
       "3  [general, principle, governing, exercise, disc...  \n",
       "4  [preceding, general, principle, inform, exerci...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['processed_doc2vec'] = data['case_text'].apply(preprocess_text_doc2vec)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "357ac856",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data[['processed_doc2vec', 'case_outcome']], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c41df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание TaggedDocument\n",
    "train_tagged = [TaggedDocument(words=text, tags=[str(tag)]) for text, tag in zip(train['processed_doc2vec'], train['case_outcome'])]\n",
    "test_tagged = [TaggedDocument(words=text, tags=[str(tag)]) for text, tag in zip(test['processed_doc2vec'], test['case_outcome'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "051016aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, workers=cores)\n",
    "model_dbow.build_vocab(train_tagged)\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle(train_tagged), total_examples=len(train_tagged), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "125dd377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.49113260781942764\n",
      "Testing F1 score: 0.3248769908599491\n"
     ]
    }
   ],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in tagged_docs])\n",
    "    return targets, regressors\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(f'Testing accuracy {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Testing F1 score: {f1_score(y_test, y_pred, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "29de9acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.4913341394598952\n",
      "Testing F1 score: 0.3265479763232657\n"
     ]
    }
   ],
   "source": [
    "random_forest_clf = RandomForestClassifier(n_estimators=500, random_state=42, n_jobs=-1)\n",
    "\n",
    "random_forest_clf.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest_clf.predict(X_test)\n",
    "\n",
    "print(f'Testing accuracy {accuracy_score(y_test, y_pred_rf)}')\n",
    "print(f'Testing F1 score: {f1_score(y_test, y_pred_rf, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba87b3e",
   "metadata": {},
   "source": [
    "Doc2Vec дал результаты ниже ожидаемого.  \n",
    "В целом, выбор метода векторизации и классификатора довольно сильно влияет на качество."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
